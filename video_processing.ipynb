{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘predicted_frames’: File exists\n",
      "mkdir: cannot create directory ‘save_frames’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir predicted_frames\n",
    "!mkdir save_frames\n",
    "\n",
    "#Run the snippets above first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "# Creating a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture('data/test_video.mp4')\n",
    "\n",
    "count=0\n",
    "while (cap.isOpened()):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    filename=str(uuid.uuid4())+\".jpg\"\n",
    "    fullpath=os.path.join(\"./save_frames\",filename)\n",
    "    cv2.imwrite(fullpath, frame)\n",
    "    count+=1\n",
    "    \n",
    "    if count==20:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t   predicted_frames  save_frames\t       video_processing.ipynb\n",
      "image.png  README.md\t     Solution_Methodology.pdf\n",
      "lib\t   requirements.txt  src\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 11:57:08.462704: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732247828.487138  112689 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732247828.494806  112689 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-22 11:57:08.519538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_path = './predicted_frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732248042.924146  112689 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6887 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected number of values returned from visualize_boxes_and_labels_on_image_array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 109\u001b[0m\n\u001b[1;32m    107\u001b[0m     image, box_to_display_str_map, additional_value \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected number of values returned from visualize_boxes_and_labels_on_image_array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m image_pil \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(np\u001b[38;5;241m.\u001b[39muint8(image_np))\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    112\u001b[0m im_width, im_height \u001b[38;5;241m=\u001b[39m image_pil\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected number of values returned from visualize_boxes_and_labels_on_image_array"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import zipfile\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "KPIs_dict = dict()\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = \"data/frozen_inference_graph.pb\"\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = \"data/labels.txt\"\n",
    "\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "# ## Load a (frozen) Tensorflow model into memory.\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "# ## Loading label map\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "# ## Helper code\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def calculate_area(x1, y1, x2, y2):\n",
    "    xDiff = abs(x1 - x2)\n",
    "    yDiff = abs(y1 - y2)\n",
    "    area = xDiff * yDiff\n",
    "    return area\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (500, 500)\n",
    "count = 0\n",
    "frame_number = 0\n",
    "cap = cv2.VideoCapture('data/test_video.mp4')\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        while cap.isOpened():\n",
    "            frame_number += 1\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            filename = str(uuid.uuid4()) + \".jpg\"\n",
    "            fullpath = os.path.join(\"./save_frames\", filename)\n",
    "            cv2.imwrite(fullpath, frame)\n",
    "            count += 1\n",
    "\n",
    "            # for testing script...\n",
    "            if count == 50:\n",
    "                break\n",
    "            # ends here\n",
    "\n",
    "            image = Image.open(fullpath)\n",
    "\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            # Visualization of the results of a detection.\n",
    "\n",
    "            result = vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=8)\n",
    "\n",
    "            # Unpack the result based on the actual number of returned values\n",
    "            if isinstance(result, tuple) and len(result) == 2:\n",
    "                image, box_to_display_str_map = result\n",
    "            elif isinstance(result, tuple) and len(result) == 3:\n",
    "                image, box_to_display_str_map, additional_value = result\n",
    "            else:\n",
    "                raise ValueError(\"Unexpected number of values returned from visualize_boxes_and_labels_on_image_array\")\n",
    "\n",
    "            image_pil = Image.fromarray(np.uint8(image_np)).convert('RGB')\n",
    "            im_width, im_height = image_pil.size\n",
    "            area_whole = im_width * im_height\n",
    "            for key, value in box_to_display_str_map.items():\n",
    "                ymin, xmin, ymax, xmax = key\n",
    "                (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "                area = calculate_area(top, left, bottom, right)\n",
    "\n",
    "                percent_area = round(area / area_whole, 2)\n",
    "                rindex = value[0].rfind(':')\n",
    "                brand_name = value[0][:rindex]\n",
    "\n",
    "                if brand_name in KPIs_dict.keys():\n",
    "                    KPIs_dict[brand_name]['count'] += 1\n",
    "                    KPIs_dict[brand_name]['area'].append(percent_area)\n",
    "                    KPIs_dict[brand_name]['frames'].append(frame_number)\n",
    "                else:\n",
    "                    KPIs_dict[brand_name] = {\"count\": 1}\n",
    "                    KPIs_dict[brand_name].update({\"area\": [percent_area]})\n",
    "                    KPIs_dict[brand_name].update({\"frames\": [frame_number]})\n",
    "\n",
    "            full_predicted_path = os.path.join(predicted_path, str(uuid.uuid4()) + \".jpg\")\n",
    "            cv2.imwrite(full_predicted_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPIs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_brand,analytics_dict in KPIs_dict.items():\n",
    "    area=analytics_dict['area']\n",
    "    response = shortest_longest_area(area)\n",
    "    KPIs_dict[each_brand].update(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_longest_area(area_list):\n",
    "    area_list.sort()\n",
    "    shortest = area_list[0]\n",
    "    longest = area_list[-1]\n",
    "    response = {\n",
    "        \"shortest\":shortest,\n",
    "        \"longest\":longest\n",
    "    }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPIs_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_projects_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
