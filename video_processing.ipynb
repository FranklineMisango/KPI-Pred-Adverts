{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘predicted_frames’: File exists\n",
      "mkdir: cannot create directory ‘save_frames’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir predicted_frames\n",
    "!mkdir save_frames\n",
    "\n",
    "#Run the snippets above first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "# Creating a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture('data/test_video.mp4')\n",
    "\n",
    "count=0\n",
    "while (cap.isOpened()):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    filename=str(uuid.uuid4())+\".jpg\"\n",
    "    fullpath=os.path.join(\"./save_frames\",filename)\n",
    "    cv2.imwrite(fullpath, frame)\n",
    "    count+=1\n",
    "    \n",
    "    if count==20:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t   predicted_frames  save_frames\t       video_processing.ipynb\n",
      "image.png  README.md\t     Solution_Methodology.pdf\n",
      "lib\t   requirements.txt  src\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 12:08:23.054929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732248503.068910  118160 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732248503.073441  118160 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-22 12:08:23.088317: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_path = './predicted_frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732248930.544020  118160 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6926 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import zipfile\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "KPIs_dict = dict()\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = \"data/frozen_inference_graph.pb\"\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = \"data/labels.txt\"\n",
    "\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "# ## Load a (frozen) Tensorflow model into memory.\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "# ## Loading label map\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "# ## Helper code\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def calculate_area(x1, y1, x2, y2):\n",
    "    xDiff = abs(x1 - x2)\n",
    "    yDiff = abs(y1 - y2)\n",
    "    area = xDiff * yDiff\n",
    "    return area\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, classes, scores, category_index, min_score_thresh=0.5):\n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] > min_score_thresh:\n",
    "            box = boxes[i]\n",
    "            class_id = classes[i]\n",
    "            score = scores[i]\n",
    "            label = category_index[class_id]['name']\n",
    "            \n",
    "            ymin, xmin, ymax, xmax = box\n",
    "            (left, right, top, bottom) = (int(xmin * image.shape[1]), int(xmax * image.shape[1]),\n",
    "                                          int(ymin * image.shape[0]), int(ymax * image.shape[0]))\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            \n",
    "            # Draw label and score\n",
    "            label_text = f\"{label}: {int(score * 100)}%\"\n",
    "            cv2.putText(image, label_text, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (500, 500)\n",
    "count = 0\n",
    "frame_number = 0\n",
    "cap = cv2.VideoCapture('data/test_video.mp4')\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        while cap.isOpened():\n",
    "            frame_number += 1\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            filename = str(uuid.uuid4()) + \".jpg\"\n",
    "            fullpath = os.path.join(\"./save_frames\", filename)\n",
    "            cv2.imwrite(fullpath, frame)\n",
    "            count += 1\n",
    "\n",
    "            # for testing script...\n",
    "            if count == 50:\n",
    "                break\n",
    "            # ends here\n",
    "\n",
    "            image = Image.open(fullpath)\n",
    "\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            # Visualization of the results of a detection.\n",
    "\n",
    "            image_np = draw_bounding_boxes(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                min_score_thresh=0.5)\n",
    "\n",
    "            image_pil = Image.fromarray(np.uint8(image_np)).convert('RGB')\n",
    "            im_width, im_height = image_pil.size\n",
    "            area_whole = im_width * im_height\n",
    "            num_detections = int(num_detections[0])  # Extract the single element from the array\n",
    "            for i in range(num_detections):\n",
    "                if scores[0][i] > 0.5:\n",
    "                    ymin, xmin, ymax, xmax = boxes[0][i]\n",
    "                    (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "                    area = calculate_area(top, left, bottom, right)\n",
    "\n",
    "                    percent_area = round(float(area) / area_whole, 2)  # Convert to regular float\n",
    "                    class_id = int(classes[0][i])\n",
    "                    label = category_index[class_id]['name']\n",
    "\n",
    "                    if label in KPIs_dict.keys():\n",
    "                        KPIs_dict[label]['count'] += 1\n",
    "                        KPIs_dict[label]['area'].append(percent_area)\n",
    "                        KPIs_dict[label]['frames'].append(frame_number)\n",
    "                    else:\n",
    "                        KPIs_dict[label] = {\"count\": 1}\n",
    "                        KPIs_dict[label].update({\"area\": [percent_area]})\n",
    "                        KPIs_dict[label].update({\"frames\": [frame_number]})\n",
    "\n",
    "            full_predicted_path = os.path.join(predicted_path, str(uuid.uuid4()) + \".jpg\")\n",
    "            cv2.imwrite(full_predicted_path, image_np)_path, image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hotstar': {'count': 9,\n",
       "  'area': [np.float32(0.16),\n",
       "   np.float32(0.16),\n",
       "   np.float32(0.21),\n",
       "   np.float32(0.18),\n",
       "   np.float32(0.15),\n",
       "   np.float32(0.34),\n",
       "   np.float32(0.31),\n",
       "   np.float32(0.17),\n",
       "   np.float32(0.16)],\n",
       "  'frames': [4, 5, 5, 6, 10, 14, 16, 31, 34]},\n",
       " 'pepsi': {'count': 2,\n",
       "  'area': [np.float32(0.0), np.float32(0.0)],\n",
       "  'frames': [46, 46]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KPIs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_longest_area(area_list):\n",
    "    area_list.sort()\n",
    "    shortest = area_list[0]\n",
    "    longest = area_list[-1]\n",
    "    response = {\n",
    "        \"shortest\":shortest,\n",
    "        \"longest\":longest\n",
    "    }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_brand,analytics_dict in KPIs_dict.items():\n",
    "    area=analytics_dict['area']\n",
    "    response = shortest_longest_area(area)\n",
    "    KPIs_dict[each_brand].update(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hotstar': {'count': 9,\n",
       "  'area': [np.float32(0.15),\n",
       "   np.float32(0.16),\n",
       "   np.float32(0.16),\n",
       "   np.float32(0.16),\n",
       "   np.float32(0.17),\n",
       "   np.float32(0.18),\n",
       "   np.float32(0.21),\n",
       "   np.float32(0.31),\n",
       "   np.float32(0.34)],\n",
       "  'frames': [4, 5, 5, 6, 10, 14, 16, 31, 34],\n",
       "  'shortest_area': np.float32(0.15),\n",
       "  'longest_area': np.float32(0.34),\n",
       "  'shortest': np.float32(0.15),\n",
       "  'longest': np.float32(0.34)},\n",
       " 'pepsi': {'count': 2,\n",
       "  'area': [np.float32(0.0), np.float32(0.0)],\n",
       "  'frames': [46, 46],\n",
       "  'shortest_area': np.float32(0.0),\n",
       "  'longest_area': np.float32(0.0),\n",
       "  'shortest': np.float32(0.0),\n",
       "  'longest': np.float32(0.0)}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KPIs_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_projects_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
